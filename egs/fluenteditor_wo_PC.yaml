## Training
accumulate_grad_batches: 1
add_word_pos: true
amp: false
audio_num_mel_bins: 80
audio_sample_rate: 22050
binarizer_cls: data_gen.tts.base_binarizer.BaseBinarizer
raw_data_dir: data/raw/vctk
processed_data_dir: data/processed/vctk
binary_data_dir: data/binary/vctk
# irectory where the datasets are located
directory: /sdc/home/xijiatian/pro/fluenteditor
check_val_every_n_epoch: 10
clip_grad_norm: 1
clip_grad_value: 0
debug: false
ds_name: vctk
ds_workers: 2
endless_ds: true
eval_max_batches: -1
lr: 0.0002
load_ckpt: ''
max_epochs: 1000
max_frames: 1548
max_input_tokens: 1550
max_sentences: 16
max_tokens: 40000
max_updates: 200000
max_valid_sentences: 1
max_valid_tokens: 60000
num_ckpt_keep: 3
num_sanity_val_steps: 5
num_spk: 1261
num_valid_plots: 10
optimizer_adam_beta1: 0.9
optimizer_adam_beta2: 0.98
posterior_start_steps: 0
print_nan_grads: false
profile_infer: false
rename_tmux: true
resume_from_checkpoint: 0
save_best: false
save_codes:
- tasks
- modules
save_f0: false
save_gt: true
scheduler: warmup
seed: 1234
sigmoid_scale: false
sort_by_len: true
task_cls: tasks.speech_editing.spec_denoiser.SpeechDenoiserTask
tb_log_interval: 100
test_input_yaml: ''
test_num: 100
test_set_name: test
train_set_name: train
train_sets: ''
two_stage: true
val_check_interval: 2000
valid_infer_interval: 2000
valid_monitor_key: val_loss
valid_monitor_mode: min
valid_set_name: valid
warmup_updates: 8000
weight_decay: 0
word_dict_size: 40500
mask_ratio: 0.12


# Mask
mask_type: 'continuous_'
training_mask_ratio: 0.80
infer_mask_ratio: 0.30


# diffusion model
diff_decoder_type: 'wavenet'
latent_cond_type: 'add'
dilation_cycle_length: 1
residual_layers: 20
residual_channels: 256
keep_bins: 80
spec_min: [ ]
spec_max: [ ]
diff_loss_type: l1
max_beta: 0.06
# diffusion
timesteps: 8
timescale: 1
schedule_type: 'vpsde'


# Modules
conv_use_pos: false
dec_dilations:
- 1
- 1
- 1
- 1
dec_ffn_kernel_size: 9
dec_inp_add_noise: false
dec_kernel_size: 5
dec_layers: 4
dec_post_net_kernel: 3
decoder_rnn_dim: 0
decoder_type: conv
detach_postflow_input: true
dropout: 0.0
dur_level: word
dur_predictor_kernel: 5
dur_predictor_layers: 3
enc_dec_norm: ln
enc_dilations:
- 1
- 1
- 1
- 1
enc_ffn_kernel_size: 5
enc_kernel_size: 5
enc_layers: 4
enc_post_net_kernel: 3
enc_pre_ln: true
enc_prenet: true
encoder_K: 8
encoder_type: conv
ffn_act: gelu
ffn_hidden_size: 768
fft_size: 1024
hidden_size: 192
hop_size: 256
latent_size: 16
layers_in_block: 2
num_heads: 2
mel_disc_hidden_size: 128
predictor_dropout: 0.2
predictor_grad: 0.1
predictor_hidden: -1
predictor_kernel: 5
predictor_layers: 5
prior_flow_hidden: 64
prior_flow_kernel_size: 3
prior_flow_n_blocks: 4
ref_norm_layer: bn
share_wn_layers: 4
text_encoder_postnet: true
use_cond_proj: false
use_gt_dur: false
use_gt_f0: false
use_latent_cond: false
use_pitch_embed: true
use_pos_embed: true
use_post_flow: true
use_prior_flow: true
use_spk_embed: true
use_spk_id: false
use_txt_cond: true
use_uv: true
use_energy_embed: false
mel_enc_layers: 4
use_conn_loss: True
use_perceptual_loss: false
mel_type: allin


# FFT
f0_max: 600
f0_min: 80
fmax: 7600
fmin: 55
frames_multiple: 1
loud_norm: false
mel_vmax: 1.5
mel_vmin: -6
min_frames: 0
noise_scale: 0.8
win_size: 1024
pitch_extractor: parselmouth
pitch_type: frame


# Infer
gen_dir_name: ''
infer: false
infer_post_glow: true
out_wav_norm: false
test_ids: [ ]
eval_mcd: False


# Loss lambda
kl_min: 0.0
kl_start_steps: 10000
lambda_commit: 0.25
lambda_energy: 0.1
lambda_f0: 1.0
lambda_kl: 1.0
lambda_mel_adv: 0.05
lambda_ph_dur: 0.1
lambda_sent_dur: 0.0
lambda_uv: 1.0
lambda_word_dur: 1.0
mel_losses: l1:0.5|ssim:0.5
# mel_losses: l1:1.0


# Vocoder
vocoder: HifiGAN
vocoder_ckpt: pretrained/hifigan_hifitts

